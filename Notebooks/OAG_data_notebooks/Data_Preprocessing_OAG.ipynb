{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEAS:\n",
    "# Remove names\n",
    "# stopwords\n",
    "# custom stopwords\n",
    "# non-alpha chars\n",
    "# lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pre-processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markberger/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (2,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.read_csv(\"../../Data/sem-search_papers_set_with_restored_abstract.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.fillna(\"None-placeholder\", inplace=True)\n",
    "full_df.drop([\"Unnamed: 0\", \"Unnamed: 0.1\", \"page_end\", \"page_start\", \"publisher\", \"issue\", \"indexed_abstract\", \n",
    "              \"volume\", \"venue\", \"doc_type\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_STOPS = {\"abstract\", \"background\", \"background.\", \"abstract.\", \"method\", \n",
    "                \"result\", \"conclusion\", \"conclusions\", \"discussion\", \"PRON\", \"registration\", \"url\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_subset = full_df.sample(50).abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace_chars(text):\n",
    "    return \" \".join(text.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z\\']', ' ', sentence)\n",
    "    \n",
    "    # remove Unicode characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use unidecode to remove accent characters and generally convert chars to their ASCII variant. Although that is not always good in small \n",
    "# amounts of text or where precision is crucial, I believe that for text similarity tasks this is generally an improvement.\n",
    "abstracts_subset = [remove_whitespace_chars(unidecode.unidecode(a)) for a in abstracts_subset if a != \"None-placeholder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_links(token):\n",
    "    if any(substring in token for substring in {\"link_type\", \"ref?\", \"=%\", \"html\", \"http\", \n",
    "                                                \"www\", \".com\", \"access_num\", \".org\", \".edu\", \"arXiv\"}):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_mostly_numeric_string(token):\n",
    "    \n",
    "    int_chars = []\n",
    "    alpha_chars = []\n",
    "    \n",
    "    for ch in token:\n",
    "        if ch.isnumeric():\n",
    "            int_chars.append(ch)\n",
    "        elif ch.isalpha():\n",
    "            alpha_chars.append(ch)\n",
    "            \n",
    "    if len(int_chars) > len(alpha_chars):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_pipeline(documents):\n",
    "    \n",
    "    # Load all the documents into a spaCy pipe.\n",
    "    docs = list(nlp.pipe(documents))\n",
    "    cleaned_docs = []\n",
    "    \n",
    "    # Lowercase + custom stopwords list + remove one character tokens + remove symbolical and punctuation tokens.\n",
    "    for doc in docs:\n",
    "        lowercased_sents_without_stops = []\n",
    "        for sent in doc.sents:\n",
    "            lowercased_lemmas_one_sent = []\n",
    "            for token in sent:\n",
    "                if not token.pos_ in {\"SYM\" ,\"PUNCT\"} \\\n",
    "                and len(token) > 1 \\\n",
    "                and not has_links(token.lower_) \\\n",
    "                and not check_for_mostly_numeric_string(token.lower_) \\\n",
    "                and not re.sub(r'[^\\w\\s]','',token.lemma_) in CUSTOM_STOPS:\n",
    "                    lowercased_lemmas_one_sent.append(token.lower_)\n",
    "                    \n",
    "            sentence = ' '.join(lowercased_lemmas_one_sent)\n",
    "            \n",
    "            lowercased_sents_without_stops.append(sentence)\n",
    "        \n",
    "        # Discard sentences with less than 4 words.\n",
    "        cleaned_docs.append([s for s in lowercased_sents_without_stops if len(s.split()) > 3])\n",
    "    \n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = create_text_pipeline(abstracts_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['prior studies have demonstrated adverse risk associated with baseline and worsening renal function in acute heart failure but none has modeled the trajectories of change in renal function and impact on outcomes',\n",
       "  'used linear mixed models of serial measurements of blood urea nitrogen and creatinine to describe trajectories of renal function in patients with acute heart failure and renal dysfunction enrolled in the placebo controlled randomized study of the selective a1 adenosine receptor antagonist rolofylline for patients hospitalized with acute decompensated heart failure and volume overload to assess treatment effect on congestion and renal function study',\n",
       "  'assessed risk of 180-day mortality and 60-day cardiovascular or renal readmission and used cox regression to determine association between renal trajectories and outcomes',\n",
       "  'compared with patients alive at days patients who died were older had lower blood pressure and ejection fraction and higher creatinine levels at baseline',\n",
       "  'on average for the entire cohort creatinine rose from days to and increased further after discharge with the trajectory dependent on the day of discharge',\n",
       "  'blood urea nitrogen creatinine and the rate of change in creatinine from baseline were the strongest independent predictors of 180-day mortality and 60-day readmission whereas the rate of change of blood urea nitrogen from baseline was not predictive of outcomes',\n",
       "  'baseline blood urea nitrogen mg dl and increase in creatinine',\n",
       "  'mg dl per day increased the risk of mortality whereas stable or decreasing creatinine was associated with reduced risk',\n",
       "  'patients with acute heart failure and renal dysfunction demonstrate variable rise and fall in renal indices during and immediately after hospitalization',\n",
       "  'risk of morbidity and mortality can be predicted based on baseline renal function and creatinine trajectory during the first days']]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_text_pipeline([abstracts_subset[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
