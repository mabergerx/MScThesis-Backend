{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0605 14:34:02.738928 4438582720 file_utils.py:35] PyTorch version 1.0.1.post2 available.\n",
      "/Users/markberger/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/markberger/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/markberger/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/markberger/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/markberger/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/markberger/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/markberger/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = pd.read_pickle(\"../Pickles/all_papers_initial_with_abstract_sents.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0605 14:34:20.026025 4438582720 SentenceTransformer.py:29] Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
      "I0605 14:34:20.027601 4438582720 SentenceTransformer.py:32] Did not find a '/' or '\\' in the name. Assume to download model from server.\n",
      "I0605 14:34:20.029026 4438582720 SentenceTransformer.py:68] Load SentenceTransformer from folder: /Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip\n",
      "I0605 14:34:20.048432 4438582720 configuration_utils.py:182] loading configuration file /Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa/config.json\n",
      "I0605 14:34:20.049967 4438582720 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0605 14:34:20.052102 4438582720 modeling_utils.py:403] loading weights file /Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa/pytorch_model.bin\n",
      "I0605 14:34:24.652250 4438582720 tokenization_utils.py:327] Model name '/Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa' is a path or url to a directory containing tokenizer files.\n",
      "I0605 14:34:24.653954 4438582720 tokenization_utils.py:395] loading file /Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa/vocab.json\n",
      "I0605 14:34:24.654617 4438582720 tokenization_utils.py:395] loading file /Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa/merges.txt\n",
      "I0605 14:34:24.655470 4438582720 tokenization_utils.py:395] loading file /Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa/added_tokens.json\n",
      "I0605 14:34:24.656595 4438582720 tokenization_utils.py:395] loading file /Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa/special_tokens_map.json\n",
      "I0605 14:34:24.657639 4438582720 tokenization_utils.py:395] loading file /Users/markberger/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-base-nli-stsb-mean-tokens.zip/0_RoBERTa/tokenizer_config.json\n",
      "I0605 14:34:24.863708 4438582720 SentenceTransformer.py:89] Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "embedder = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')\n",
    "\n",
    "# # Corpus with example sentences\n",
    "# corpus = ['A man is eating food.',\n",
    "#           'A man is eating a piece of bread.',\n",
    "#           'The girl is carrying a baby.',\n",
    "#           'A man is riding a horse.',\n",
    "#           'A woman is playing violin.',\n",
    "#           'Two men pushed carts through the woods.',\n",
    "#           'A man is riding a white horse on an enclosed ground.',\n",
    "#           'A monkey is playing drums.',\n",
    "#           'A cheetah is running behind its prey.',\n",
    "#           'Hyenas are hunting on an animal.'\n",
    "#           ]\n",
    "# corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# # # Query sentences:\n",
    "# queries = ['A cheetah chases prey on across a field.']\n",
    "# query_embeddings = embedder.encode(queries)\n",
    "\n",
    "# # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "# closest_n = 5\n",
    "# for query, query_embedding in zip(queries, query_embeddings):\n",
    "#     distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "    \n",
    "#     results = zip(range(len(distances)), distances)\n",
    "#     results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "#     print(\"\\n\\n======================\\n\\n\")\n",
    "#     print(\"Query:\", query)\n",
    "#     print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "#     for idx, distance in results[0:closest_n]:\n",
    "#         print(corpus[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>format</th>\n",
       "      <th>subjects</th>\n",
       "      <th>za_id</th>\n",
       "      <th>uri</th>\n",
       "      <th>full_sentences_path</th>\n",
       "      <th>full_scibert_embedding_path</th>\n",
       "      <th>abstract_sents</th>\n",
       "      <th>abstract_and_title_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Metric-Optimized Example Weights</td>\n",
       "      <td>Real-world machine learning applications oft...</td>\n",
       "      <td>2018-05-27T00:00:00+00:00</td>\n",
       "      <td>[{'first_name': 'Sen', 'last_name': 'Zhao', 'f...</td>\n",
       "      <td>scientific paper</td>\n",
       "      <td>[stat.ML, cs.AI, cs.LG]</td>\n",
       "      <td>249ad73104a89386bba1b9c5895f2657c319ec03</td>\n",
       "      <td>https://arxiv.org/abs/1805.10582</td>\n",
       "      <td>../zetaobjects_v1/249a/249ad73104a89386bba1b9c...</td>\n",
       "      <td>../zetaobjects_v1/embeddings/249a/249ad73104a8...</td>\n",
       "      <td>[Real-world machine learning applications ofte...</td>\n",
       "      <td>[Metric-Optimized Example Weights, Real-world ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "71  Metric-Optimized Example Weights   \n",
       "\n",
       "                                             abstract  \\\n",
       "71    Real-world machine learning applications oft...   \n",
       "\n",
       "                         date  \\\n",
       "71  2018-05-27T00:00:00+00:00   \n",
       "\n",
       "                                              authors            format  \\\n",
       "71  [{'first_name': 'Sen', 'last_name': 'Zhao', 'f...  scientific paper   \n",
       "\n",
       "                   subjects                                     za_id  \\\n",
       "71  [stat.ML, cs.AI, cs.LG]  249ad73104a89386bba1b9c5895f2657c319ec03   \n",
       "\n",
       "                                 uri  \\\n",
       "71  https://arxiv.org/abs/1805.10582   \n",
       "\n",
       "                                  full_sentences_path  \\\n",
       "71  ../zetaobjects_v1/249a/249ad73104a89386bba1b9c...   \n",
       "\n",
       "                          full_scibert_embedding_path  \\\n",
       "71  ../zetaobjects_v1/embeddings/249a/249ad73104a8...   \n",
       "\n",
       "                                       abstract_sents  \\\n",
       "71  [Real-world machine learning applications ofte...   \n",
       "\n",
       "                             abstract_and_title_sents  \n",
       "71  [Metric-Optimized Example Weights, Real-world ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_papers.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract_and_title_sents</th>\n",
       "      <th>abstract_sents</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Deep neural networks have gained tremendous ...</td>\n",
       "      <td>[Unsupervised Representation Learning by Predi...</td>\n",
       "      <td>[Deep neural networks have gained tremendous s...</td>\n",
       "      <td>Unsupervised Representation Learning by Predic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Many visual surveillance tasks, e.g.video su...</td>\n",
       "      <td>[Learning from Multiple Sources for Video Summ...</td>\n",
       "      <td>[Many visual surveillance tasks, e.g.video sum...</td>\n",
       "      <td>Learning from Multiple Sources for Video Summa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>We develop a new approach that computes appr...</td>\n",
       "      <td>[Computing Strong Game-Theoretic Strategies in...</td>\n",
       "      <td>[We develop a new approach that computes appro...</td>\n",
       "      <td>Computing Strong Game-Theoretic Strategies in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Texture analysis is an important field of in...</td>\n",
       "      <td>[Image decomposition with anisotropic diffusio...</td>\n",
       "      <td>[Texture analysis is an important field of inv...</td>\n",
       "      <td>Image decomposition with anisotropic diffusion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>We explore recurrent encoder multi-decoder n...</td>\n",
       "      <td>[Recurrent Semi-supervised Classification and ...</td>\n",
       "      <td>[We explore recurrent encoder multi-decoder ne...</td>\n",
       "      <td>Recurrent Semi-supervised Classification and C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              abstract  \\\n",
       "391    Deep neural networks have gained tremendous ...   \n",
       "62     Many visual surveillance tasks, e.g.video su...   \n",
       "265    We develop a new approach that computes appr...   \n",
       "155    Texture analysis is an important field of in...   \n",
       "35     We explore recurrent encoder multi-decoder n...   \n",
       "\n",
       "                              abstract_and_title_sents  \\\n",
       "391  [Unsupervised Representation Learning by Predi...   \n",
       "62   [Learning from Multiple Sources for Video Summ...   \n",
       "265  [Computing Strong Game-Theoretic Strategies in...   \n",
       "155  [Image decomposition with anisotropic diffusio...   \n",
       "35   [Recurrent Semi-supervised Classification and ...   \n",
       "\n",
       "                                        abstract_sents  \\\n",
       "391  [Deep neural networks have gained tremendous s...   \n",
       "62   [Many visual surveillance tasks, e.g.video sum...   \n",
       "265  [We develop a new approach that computes appro...   \n",
       "155  [Texture analysis is an important field of inv...   \n",
       "35   [We explore recurrent encoder multi-decoder ne...   \n",
       "\n",
       "                                                 title  \n",
       "391  Unsupervised Representation Learning by Predic...  \n",
       "62   Learning from Multiple Sources for Video Summa...  \n",
       "265  Computing Strong Game-Theoretic Strategies in ...  \n",
       "155  Image decomposition with anisotropic diffusion...  \n",
       "35   Recurrent Semi-supervised Classification and C...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_papers.sample(5)[[\"abstract\", \"abstract_and_title_sents\", \"abstract_sents\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  To ensure readability, text is often written and presented with due formatting. These text formatting devices help the writer to effectively convey the narrative. At the same time, these help the readers pick up the structure of the discourse and comprehend the conveyed information. There have been a number of linguistic theories on discourse structure of text. However, these theories only consider unformatted text. Multimedia text contains rich formatting features which can be leveraged for various NLP tasks. In this paper, we study some of these discourse features in multimedia text and what communicative function they fulfil in the context. We examine how these multimedia discourse features can be used to improve an information extraction system. We show that the discourse and text layout features provide information that is complementary to lexical semantic information commonly used for information extraction. As a case study, we use these features to harvest structured subject knowledge of geometry from textbooks. We show that the harvested structured knowledge can be used to improve an existing solver for geometry problems, making it more accurate as well as more explainable. '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_papers.sample(1)[\"abstract\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_sentences_embedding(sentences, model=embedder):\n",
    "    embeddings = model.encode(sentences)\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = all_papers.sample(1)[\"abstract_sents\"].iloc[0]\n",
    "sample2 = all_papers.sample(1)[\"abstract_sents\"].iloc[0]\n",
    "sample3 = all_papers.sample(1)[\"abstract_sents\"].iloc[0]\n",
    "sample4 = all_papers.sample(1)[\"abstract_sents\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(sample1)\n",
    "# print(\"---------------------\")\n",
    "# pprint(sample2)\n",
    "# print(\"---------------------\")\n",
    "# pprint(sample3)\n",
    "# print(\"---------------------\")\n",
    "# pprint(sample4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    s = re.sub(r'\\.','',sentence)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    initial_split = text.split(\".\")\n",
    "    return [preprocess_sentence(s) for s in initial_split if s != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_sample1 = split_text(\"The Belyayev circle believed in a national style of classical music, based on the achievements of the composer group The Five which preceded it. One important difference between composers in the Belyayev circle and their counterparts in the Five was an acceptance in the necessity of Western-styled academic training; this was an attitude passed down by Rimsky-Korsakov, who taught many of the composers in the circle at the Saint Petersburg Conservatory. While these composers were more open to Western compositional practices and influences, especially through the music of Pyotr Ilyich Tchaikovsky, they closely followed many of the compositional practices of the Five to the point of mannerism, especially in their depiction of folkloric subject matter.\")\n",
    "tribe_sample1 = split_text(\"They are known for both their prowess in warfare and trophy-keeping practices, as well as their ability to interact and accommodate non-native peoples. They maintained a nomadic existence and frequently intermarried with other tribes.\")\n",
    "tribe_sample2 = split_text(\"The Tupi people inhabited almost all of Brazil's coast when the Portuguese first arrived there. In 1500, their population was estimated at 1 million people, nearly equal to the population of Portugal at the time. They were divided into tribes, each tribe numbering from 300 to 2,000 people.\")\n",
    "nationality_sample3 = split_text(\"The ideologies associated with (Romantic) Nationalism of the 19th and 20th centuries never really caught on in the Netherlands, and this, together with being a relatively mono-ethnic society up until the late 1950s, has led to a relatively obscure use of the terms nation and ethnicity as both were largely overlapping in practice. \")\n",
    "music_sample2 = split_text(\"Tchaikovsky displayed a wide stylistic and emotional range, from light salon works to grand symphonies. Some of his works, such as the Variations on a Rococo Theme, employ a Classical form reminiscent of 18th-century composers such as Mozart (his favorite composer).\")\n",
    "company_example1 = split_text(\"The four networks are often grouped together for a number of reasons; they are each comparable in size relative to the rest of the market, both in terms of revenue and workforce; they are each considered equal in their ability to provide a wide scope of quality professional services to their clients; and, among those looking to start a career in professional services, particularly accounting, they are considered equally attractive networks to work in, because of the frequency with which these firms engage with Fortune 500 companies.\")\n",
    "company_example2 = split_text(\"Google LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, search engine, cloud computing, software, and hardware.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Belyayev circle believed in a national style of classical music, based on the achievements of the composer group The Five which preceded it',\n",
       " ' One important difference between composers in the Belyayev circle and their counterparts in the Five was an acceptance in the necessity of Western-styled academic training; this was an attitude passed down by Rimsky-Korsakov, who taught many of the composers in the circle at the Saint Petersburg Conservatory',\n",
       " ' While these composers were more open to Western compositional practices and influences, especially through the music of Pyotr Ilyich Tchaikovsky, they closely followed many of the compositional practices of the Five to the point of mannerism, especially in their depiction of folkloric subject matter']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [music_sample1, tribe_sample1, tribe_sample2, nationality_sample3, music_sample2, company_example1, company_example2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = [get_average_sentences_embedding(sents) for sents in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Large technology companies earn way too much money.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "The four networks are often grouped together for a number of reasons; they are each comparable in size relative to the rest of the market, both in terms of revenue and workforce; they are each considered equal in their ability to provide a wide scope of quality professional services to their clients; and, among those looking to start a career in professional services, particularly accounting, they are considered equally attractive networks to work in, because of the frequency with which these firms engage with Fortune 500 companies (Score: 0.3144)\n",
      "Google LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, search engine, cloud computing, software, and hardware (Score: 0.2392)\n",
      "Tchaikovsky displayed a wide stylistic and emotional range, from light salon works to grand symphonies  Some of his works, such as the Variations on a Rococo Theme, employ a Classical form reminiscent of 18th-century composers such as Mozart (his favorite composer) (Score: 0.2023)\n",
      "The ideologies associated with (Romantic) Nationalism of the 19th and 20th centuries never really caught on in the Netherlands, and this, together with being a relatively mono-ethnic society up until the late 1950s, has led to a relatively obscure use of the terms nation and ethnicity as both were largely overlapping in practice   (Score: 0.0935)\n",
      "The Belyayev circle believed in a national style of classical music, based on the achievements of the composer group The Five which preceded it  One important difference between composers in the Belyayev circle and their counterparts in the Five was an acceptance in the necessity of Western-styled academic training; this was an attitude passed down by Rimsky-Korsakov, who taught many of the composers in the circle at the Saint Petersburg Conservatory  While these composers were more open to Western compositional practices and influences, especially through the music of Pyotr Ilyich Tchaikovsky, they closely followed many of the compositional practices of the Five to the point of mannerism, especially in their depiction of folkloric subject matter (Score: 0.0622)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: The classical music is very influential on a lot of art movements.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Tchaikovsky displayed a wide stylistic and emotional range, from light salon works to grand symphonies  Some of his works, such as the Variations on a Rococo Theme, employ a Classical form reminiscent of 18th-century composers such as Mozart (his favorite composer) (Score: 0.6757)\n",
      "The Belyayev circle believed in a national style of classical music, based on the achievements of the composer group The Five which preceded it  One important difference between composers in the Belyayev circle and their counterparts in the Five was an acceptance in the necessity of Western-styled academic training; this was an attitude passed down by Rimsky-Korsakov, who taught many of the composers in the circle at the Saint Petersburg Conservatory  While these composers were more open to Western compositional practices and influences, especially through the music of Pyotr Ilyich Tchaikovsky, they closely followed many of the compositional practices of the Five to the point of mannerism, especially in their depiction of folkloric subject matter (Score: 0.5447)\n",
      "The four networks are often grouped together for a number of reasons; they are each comparable in size relative to the rest of the market, both in terms of revenue and workforce; they are each considered equal in their ability to provide a wide scope of quality professional services to their clients; and, among those looking to start a career in professional services, particularly accounting, they are considered equally attractive networks to work in, because of the frequency with which these firms engage with Fortune 500 companies (Score: 0.2252)\n",
      "Google LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, search engine, cloud computing, software, and hardware (Score: 0.2128)\n",
      "They are known for both their prowess in warfare and trophy-keeping practices, as well as their ability to interact and accommodate non-native peoples  They maintained a nomadic existence and frequently intermarried with other tribes (Score: 0.1438)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: There are multiple nationalitites present in this rural country.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "The Tupi people inhabited almost all of Brazil's coast when the Portuguese first arrived there  In 1500, their population was estimated at 1 million people, nearly equal to the population of Portugal at the time  They were divided into tribes, each tribe numbering from 300 to 2,000 people (Score: 0.3610)\n",
      "They are known for both their prowess in warfare and trophy-keeping practices, as well as their ability to interact and accommodate non-native peoples  They maintained a nomadic existence and frequently intermarried with other tribes (Score: 0.3589)\n",
      "The ideologies associated with (Romantic) Nationalism of the 19th and 20th centuries never really caught on in the Netherlands, and this, together with being a relatively mono-ethnic society up until the late 1950s, has led to a relatively obscure use of the terms nation and ethnicity as both were largely overlapping in practice   (Score: 0.3166)\n",
      "The four networks are often grouped together for a number of reasons; they are each comparable in size relative to the rest of the market, both in terms of revenue and workforce; they are each considered equal in their ability to provide a wide scope of quality professional services to their clients; and, among those looking to start a career in professional services, particularly accounting, they are considered equally attractive networks to work in, because of the frequency with which these firms engage with Fortune 500 companies (Score: 0.2307)\n",
      "The Belyayev circle believed in a national style of classical music, based on the achievements of the composer group The Five which preceded it  One important difference between composers in the Belyayev circle and their counterparts in the Five was an acceptance in the necessity of Western-styled academic training; this was an attitude passed down by Rimsky-Korsakov, who taught many of the composers in the circle at the Saint Petersburg Conservatory  While these composers were more open to Western compositional practices and influences, especially through the music of Pyotr Ilyich Tchaikovsky, they closely followed many of the compositional practices of the Five to the point of mannerism, especially in their depiction of folkloric subject matter (Score: 0.2097)\n"
     ]
    }
   ],
   "source": [
    "# # Query sentences:\n",
    "queries = ['Large technology companies earn way too much money.', 'The classical music is very influential on a lot of art movements.', 'There are multiple nationalitites present in this rural country.']\n",
    "query_embeddings = embedder.encode(queries)\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "closest_n = 5\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "    \n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(' '.join(corpus[idx]), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13890238]\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - scipy.spatial.distance.cdist([query_embeddings[0]], [corpus_embeddings[6]], \"cosine\")[0]\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save abstract average SBERT embedding + title SBERT embedding to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_papers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1e043ad68402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_papers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_papers' is not defined"
     ]
    }
   ],
   "source": [
    "all_papers.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [[2,3,1], [4,5,2]]\n",
    "title = [7,1,2]\n",
    "abstracts_and_title = [[7,1,2], [2,3,1], [4,5,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3. , 4. , 1.5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abstracts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.33333333, 3.        , 1.66666667])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abstracts_and_title, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.  , 2.5 , 1.75])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.mean(abstracts, axis=0), title], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.333333333333333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_embedding_abstract_and_title(abstract, title, strategy=\"merge\", model=embedder):\n",
    "\n",
    "    title_embedding = model.encode(title)\n",
    "    \n",
    "    if strategy == \"merge\":\n",
    "        abstract_embeddings = model.encode(abstract)\n",
    "        merged = np.concatenate((title_embedding, abstract_embeddings), axis=0)\n",
    "        average = np.mean(merged, axis=0)\n",
    "    elif strategy == \"separate\":\n",
    "        average_abstract = get_average_sentences_embedding(abstract)\n",
    "        average = np.mean([average_abstract, title_embedding[0]], axis=0)\n",
    "    else:\n",
    "        print(\"Warning: wrong strategy is used. Use either 'merge' or 'separate'. Proceeding using the 'merge' strategy.\")\n",
    "        abstract_embeddings = model.encode(abstract)\n",
    "        merged = np.concatenate((title_embedding, abstract_embeddings), axis=0)\n",
    "        average = np.mean(merged, axis=0)\n",
    "        \n",
    "    return average\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_abstract_sbert_embedding(row, emb_strategy=\"merge\"):\n",
    "    title = row[\"title\"]\n",
    "    abstract = row[\"abstract_sents\"]\n",
    "    za_id = row[\"za_id\"]\n",
    "    za_id_short = za_id[:4]\n",
    "    \n",
    "    path_to_sbert_representation = row[\"full_sentences_path\"][:-22]\n",
    "    \n",
    "    folder_merge = row[\"full_scibert_embedding_path\"].replace(\"zetaobjects_v1/embeddings/\", \"zetaobjects_v1/sbert_embedings_abstract_title_merged/\").replace(\"/document_embedding.npy\", \"\")\n",
    "    folder_separate = row[\"full_scibert_embedding_path\"].replace(\"zetaobjects_v1/embeddings/\", \"zetaobjects_v1/sbert_embedings_abstract_title_separate/\").replace(\"/document_embedding.npy\", \"\")\n",
    "    embedding = calculate_average_embedding_abstract_and_title(abstract, title, strategy=emb_strategy)\n",
    "    if emb_strategy==\"merge\":\n",
    "        if not os.path.exists(folder_merge):\n",
    "            os.makedirs(folder_merge)\n",
    "        np.save(f\"{folder_merge}/embedding.npy\", embedding)\n",
    "            \n",
    "        with open(f\"{path_to_sbert_representation}sbert_embedding_merged\", 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"version\":\"1.0.0\",\"value\":{\"pointer\":f\"/data/zetaobjects_v1/sbert_embedings_abstract_title_merged/{za_id_short}/{za_id}/embedding.npy\"},\"type\":\"pointer\"}, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    elif emb_strategy==\"separate\":\n",
    "        if not os.path.exists(folder_separate):\n",
    "            os.makedirs(folder_separate)\n",
    "        np.save(f\"{folder_separate}/embedding.npy\", embedding) \n",
    "        \n",
    "        with open(f\"{path_to_sbert_representation}sbert_embedding_separate\", 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"version\":\"1.0.0\",\"value\":{\"pointer\":f\"/data/zetaobjects_v1/sbert_embedings_abstract_title_separate/{za_id_short}/{za_id}/embedding.npy\"},\"type\":\"pointer\"}, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in all_papers.iterrows():\n",
    "#     store_abstract_sbert_embedding(row, \"merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
